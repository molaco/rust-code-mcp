---
title: "Hybrid Search Implementation Analysis - Rust Code MCP"
date: "2025-10-22"
version: "1.0"
project: "file-search-mcp (rust-code-mcp)"

overview:
  summary: |
    Complete hybrid search system combining Tantivy BM25 (lexical) with Qdrant vector (semantic) search,
    merged using Reciprocal Rank Fusion (RRF) algorithm. The system provides configurable weighting,
    automatic fallback mechanisms, and parameter tuning capabilities.

  architecture: |
    UnifiedIndexer → [Tantivy BM25 Index + Qdrant Vector Store] → HybridSearch → RRF Merge → Ranked Results

key_components:

  1_unified_indexer:
    file: "src/indexing/unified.rs"
    description: "Single indexing pipeline that populates both Tantivy and Qdrant simultaneously"
    responsibilities:
      - "Parse Rust code with tree-sitter"
      - "Chunk code by semantic units (functions, structs, etc.)"
      - "Generate embeddings using fastembed (all-MiniLM-L6-v2)"
      - "Index to Tantivy for BM25 search"
      - "Index to Qdrant for vector similarity search"
      - "Track changes with metadata cache for incremental updates"
    key_features:
      - "Dual indexing in single pass"
      - "Incremental indexing with Merkle tree change detection"
      - "Optimized memory budgets based on codebase size"
      - "Security scanning for secrets"
    lines: "src/indexing/unified.rs:1-200+"

  2_bm25_search:
    file: "src/search/bm25.rs"
    description: "Tantivy-based BM25 lexical search for code chunks"
    implementation:
      algorithm: "BM25 (Best Match 25)"
      library: "Tantivy"
      schema: "ChunkSchema (src/schema.rs:84-179)"
      indexed_fields:
        - field: "content"
          description: "Code content"
          weight: "Standard"
        - field: "symbol_name"
          description: "Function/struct/trait names"
          weight: "Standard"
        - field: "docstring"
          description: "Documentation strings"
          weight: "Standard"
      storage_fields:
        - "chunk_id (UUID)"
        - "chunk_json (full CodeChunk)"
        - "symbol_kind"
        - "file_path"
        - "module_path"

    key_methods:
      search:
        signature: "search(&self, query: &str, limit: usize) -> Result<Vec<(ChunkId, f32, CodeChunk)>>"
        line_range: "68-121"
        description: "Multi-field query parser searching content, symbol_name, and docstring"
        returns: "Vec of (chunk_id, bm25_score, chunk)"

      reload:
        signature: "reload(&mut self) -> Result<()>"
        line_range: "138-141"
        description: "Reload index reader after new documents committed"

  3_vector_search:
    file: "src/vector_store/mod.rs"
    description: "Qdrant-based semantic vector search"
    implementation:
      database: "Qdrant"
      embedding_model: "all-MiniLM-L6-v2 (384 dimensions)"
      embedding_library: "fastembed-rs"
      similarity_metric: "Cosine distance"
      hnsw_config:
        m: 16
        ef_construct: 100
        full_scan_threshold: 10000
        max_indexing_threads: 4

    key_methods:
      upsert_chunks:
        signature: "upsert_chunks(&self, chunks_with_embeddings: Vec<(ChunkId, Embedding, CodeChunk)>) -> Result<()>"
        line_range: "179-229"
        description: "Batch upsert chunks with embeddings to Qdrant"
        batch_size: 100

      search:
        signature: "search(&self, query_vector: Embedding, limit: usize) -> Result<Vec<SearchResult>>"
        line_range: "232-291"
        description: "Semantic similarity search using query embedding"
        returns: "Vec<SearchResult> with chunk_id, score, and chunk"

  4_hybrid_search:
    file: "src/search/mod.rs"
    description: "Main hybrid search orchestrator combining BM25 and vector results"

    configuration:
      struct: "HybridSearchConfig"
      line_range: "20-41"
      parameters:
        bm25_weight:
          type: "f32"
          default: 0.5
          range: "0.0 to 1.0"
          description: "Weight for BM25 results in RRF scoring"

        vector_weight:
          type: "f32"
          default: 0.5
          range: "0.0 to 1.0"
          description: "Weight for vector results in RRF scoring"

        rrf_k:
          type: "f32"
          default: 60.0
          typical_range: "10.0 to 100.0"
          description: "RRF constant parameter (higher = less emphasis on rank position)"

        candidate_count:
          type: "usize"
          default: 100
          description: "Number of candidates to fetch from each search engine before RRF"

    key_methods:
      search:
        signature: "search(&self, query: &str, limit: usize) -> Result<Vec<SearchResult>>"
        line_range: "129-135"
        description: "Perform hybrid search with default RRF k parameter"
        flow:
          - "Run BM25 and vector search in parallel"
          - "Apply RRF merging with configured weights"
          - "Return top N results"

      search_with_k:
        signature: "search_with_k(&self, query: &str, limit: usize, rrf_k: f32) -> Result<Vec<SearchResult>>"
        line_range: "140-180"
        description: "Perform hybrid search with custom RRF k (for tuning)"
        parallel_execution:
          - task: "Vector search"
            executor: "tokio async"
          - task: "BM25 search"
            executor: "tokio::spawn_blocking (sync wrapper)"

      reciprocal_rank_fusion_with_k:
        signature: "reciprocal_rank_fusion_with_k(&self, vector_results: &[VectorSearchResult], bm25_results: &[(ChunkId, f32, CodeChunk)], k: f32) -> Vec<SearchResult>"
        line_range: "196-263"
        description: "Core RRF algorithm implementation"

rrf_algorithm:
  name: "Reciprocal Rank Fusion"
  file: "src/search/mod.rs:196-263"

  formula:
    mathematical: |
      For each chunk appearing in results:
        score(chunk) = Σ [weight_i / (k + rank_i)]

      Where:
        - k = RRF constant (default 60.0)
        - rank_i = 1-based rank in results list i
        - weight_i = configured weight for search engine i

  implementation:
    language: "Rust"
    data_structure: "HashMap<ChunkId, RrfScore>"

    steps:
      1_initialize:
        description: "Create empty HashMap for accumulating scores"
        code_line: 203

      2_process_vector_results:
        description: "Iterate through vector search results by rank"
        lines: "206-221"
        formula: "rrf_score = 1.0 / (k + (rank + 1))"
        weighting: "rrf_score * vector_weight"
        stored_metadata:
          - "vector_score (similarity score)"
          - "vector_rank (1-based position)"

      3_process_bm25_results:
        description: "Iterate through BM25 search results by rank"
        lines: "224-239"
        formula: "rrf_score = 1.0 / (k + (rank + 1))"
        weighting: "rrf_score * bm25_weight"
        stored_metadata:
          - "bm25_score (BM25 relevance score)"
          - "bm25_rank (1-based position)"

      4_merge_and_sort:
        description: "Convert HashMap to Vec and sort by combined RRF score"
        lines: "242-262"
        sort_order: "Descending (highest score first)"

  key_characteristics:
    - "Rank-based fusion (not score-based)"
    - "Handles chunks appearing in only one result set"
    - "Preserves individual scores for transparency"
    - "Configurable weights allow tuning BM25 vs vector emphasis"

result_structure:
  struct: "SearchResult"
  file: "src/search/mod.rs:44-60"

  fields:
    chunk_id:
      type: "ChunkId (UUID)"
      description: "Unique identifier for code chunk"

    score:
      type: "f32"
      description: "Combined RRF score"
      calculation: "Sum of weighted RRF contributions"

    bm25_score:
      type: "Option<f32>"
      description: "Raw BM25 score (if found in BM25 results)"

    vector_score:
      type: "Option<f32>"
      description: "Cosine similarity score (if found in vector results)"

    bm25_rank:
      type: "Option<usize>"
      description: "1-based rank in BM25 results"

    vector_rank:
      type: "Option<usize>"
      description: "1-based rank in vector results"

    chunk:
      type: "CodeChunk"
      description: "Full code chunk with context"
      includes:
        - "content (code text)"
        - "context (file_path, symbol_name, docstring, etc.)"
        - "overlap_prev/next (for context expansion)"

search_flow:
  1_query_input:
    description: "User provides natural language query"
    example: "parse command line arguments"

  2_parallel_search:
    bm25_path:
      - step: "Parse query with QueryParser"
        fields: "[content, symbol_name, docstring]"
      - step: "Execute BM25 search in Tantivy"
        output: "Vec<(ChunkId, f32, CodeChunk)>"
      - step: "Run in spawn_blocking (sync operation)"

    vector_path:
      - step: "Generate query embedding"
        model: "all-MiniLM-L6-v2"
        output: "384-dimensional vector"
      - step: "Search Qdrant with cosine similarity"
        output: "Vec<SearchResult>"
      - step: "Run async in tokio"

    synchronization: "tokio::join! awaits both futures"

  3_rrf_fusion:
    input:
      - "BM25 results (ranked by BM25 score)"
      - "Vector results (ranked by cosine similarity)"

    process:
      - "Create HashMap keyed by ChunkId"
      - "Accumulate weighted RRF scores from each source"
      - "Preserve metadata (ranks, original scores)"

    output: "Unified Vec<SearchResult> sorted by RRF score"

  4_return_top_n:
    description: "Take top N results and return to caller"
    format: "Vec<SearchResult> with all metadata"

resilient_search:
  file: "src/search/resilient.rs"
  description: "Automatic fallback wrapper for production reliability"

  features:
    graceful_degradation:
      - "If vector search fails → BM25-only mode"
      - "If BM25 fails → vector-only mode"
      - "If both fail → clear error message"

    fallback_tracking:
      mechanism: "AtomicBool flag"
      purpose: "Monitor system health and degraded mode status"

    retry_logic:
      - "Reset fallback mode on successful hybrid search"
      - "Track which components are functional"

  key_methods:
    search:
      signature: "search(&self, query: &str, limit: usize) -> Result<Vec<SearchResult>>"
      lines: "54-68"
      behavior: "Try hybrid, fallback to single mode if needed"

    try_hybrid_search:
      signature: "try_hybrid_search(&self, query: &str, limit: usize) -> Result<Vec<SearchResult>>"
      lines: "76-106"
      parallel_execution: "tokio::join! both searches"
      error_handling: "Pattern match on (BM25 result, Vector result)"

parameter_tuning:
  file: "src/search/rrf_tuner.rs"
  description: "Framework for optimizing RRF k parameter"

  tuner_struct:
    name: "RRFTuner"
    test_queries: "Vec<TestQuery>"
    default_queries: "8 Rust-specific test queries"

  test_query_structure:
    query: "Natural language search query"
    relevant_chunk_ids: "Ground truth list of relevant symbol names"
    examples:
      - query: "parse command line arguments"
        relevant: "[clap_parser, parse_args, Args]"
      - query: "vector search with embeddings"
        relevant: "[VectorStore, search, embeddings]"

  tuning_process:
    method: "tune_k"
    k_values_tested: "[10.0, 20.0, 40.0, 60.0, 80.0, 100.0]"
    metric: "NDCG@10 (Normalized Discounted Cumulative Gain)"

    algorithm:
      - "For each k value:"
      - "  For each test query:"
      - "    Execute search_with_k(query, 20, k)"
      - "    Calculate NDCG@10"
      - "  Average NDCG across all queries"
      - "Return k with highest average NDCG"

    output:
      struct: "TuningResult"
      fields:
        - "best_k: f32"
        - "best_ndcg: f64"
        - "k_values_tested: Vec<(f32, f64)>"

  evaluation_metrics:
    ndcg_at_10:
      formula: "DCG@10 / IDCG@10"
      description: "Ranking quality (0-1, higher better)"
      lines: "219-239"

    mrr:
      formula: "1 / rank_of_first_relevant"
      description: "Mean Reciprocal Rank (0-1, higher better)"
      lines: "245-251"

    map:
      formula: "Average Precision across all queries"
      description: "Mean Average Precision"
      lines: "254-271"

    recall_at_k:
      formula: "relevant_found / total_relevant"
      description: "Recall@20"
      lines: "274-286"

    precision_at_k:
      formula: "relevant_found / k"
      description: "Precision@10"
      lines: "289-297"

configuration_tuning:
  weight_adjustment:
    purpose: "Balance BM25 vs vector search based on query type"

    scenarios:
      exact_match_queries:
        description: "Searching for specific function names, APIs"
        recommended: "bm25_weight: 0.7, vector_weight: 0.3"
        reason: "BM25 better for exact lexical matches"

      conceptual_queries:
        description: "Searching for functionality, patterns, concepts"
        recommended: "bm25_weight: 0.3, vector_weight: 0.7"
        reason: "Vector search better for semantic understanding"

      balanced:
        description: "General purpose, mixed queries"
        recommended: "bm25_weight: 0.5, vector_weight: 0.5"
        reason: "Equal importance to both approaches"

  rrf_k_parameter:
    purpose: "Control sensitivity to rank position differences"

    effects:
      low_k: "10-20"
      behavior: "Higher emphasis on top-ranked results"
      use_case: "When top results highly reliable"

      medium_k: "40-60"
      behavior: "Balanced rank importance (default: 60)"
      use_case: "General purpose, standard RRF"

      high_k: "80-100"
      behavior: "Lower emphasis on rank position"
      use_case: "When result order less reliable"

  candidate_count:
    purpose: "Number of results to fetch before RRF"
    default: 100
    tradeoff:
      higher_values:
        pros: "More comprehensive merging, better recall"
        cons: "Slower search, more computation"
      lower_values:
        pros: "Faster search"
        cons: "Might miss relevant results in fusion"

integration_points:

  search_tool_mcp:
    file: "src/tools/search_tool.rs"
    tool_name: "search"
    lines: "236-369"

    workflow:
      1: "Create UnifiedIndexer for directory"
      2: "Run incremental indexing (only changed files)"
      3: "Create HybridSearch instance"
      4: "Execute hybrid search with query"
      5: "Format and return results"

    features:
      - "Automatic collection naming based on directory"
      - "Background sync manager integration"
      - "Detailed result formatting with scores"

  get_similar_code_tool:
    file: "src/tools/search_tool.rs"
    tool_name: "get_similar_code"
    lines: "858-971"
    mode: "Vector-only search"
    use_case: "Semantic code similarity without lexical matching"

  health_check:
    file: "src/tools/health_tool.rs"
    purpose: "Monitor BM25, Qdrant, and Merkle tree health"
    checks:
      - "BM25 index accessibility"
      - "Qdrant connection and collection status"
      - "Merkle tree integrity"

performance_characteristics:

  indexing:
    dual_indexing: "Single pass populates both Tantivy and Qdrant"
    incremental: "Merkle tree-based change detection"
    optimization:
      - "Metadata cache for file change tracking"
      - "Batch embedding generation"
      - "Batch Qdrant upserts (100 chunks)"
      - "Configurable memory budgets"

  search:
    parallel_execution: "BM25 and vector search run concurrently"
    typical_latency:
      bm25: "< 50ms (local Tantivy index)"
      vector: "< 100ms (Qdrant HNSW)"
      rrf_merge: "< 10ms (in-memory HashMap)"
      total: "~100-150ms for 100 candidates"

    scalability:
      small_codebase: "< 100k LOC, < 1000 chunks, near-instant"
      medium_codebase: "100k-1M LOC, 1k-10k chunks, < 200ms"
      large_codebase: "1M+ LOC, 10k+ chunks, < 500ms"

code_locations:
  core_modules:
    - path: "src/search/mod.rs"
      description: "Main hybrid search implementation"
      key_structs: "[HybridSearch, HybridSearchConfig, SearchResult]"
      lines_of_interest: "94-354"

    - path: "src/search/bm25.rs"
      description: "BM25 lexical search with Tantivy"
      key_structs: "[Bm25Search]"
      lines_of_interest: "13-154"

    - path: "src/search/rrf_tuner.rs"
      description: "RRF parameter tuning framework"
      key_structs: "[RRFTuner, TestQuery, TuningResult, EvaluationMetrics]"
      lines_of_interest: "19-340"

    - path: "src/search/resilient.rs"
      description: "Resilient wrapper with fallback"
      key_structs: "[ResilientHybridSearch]"
      lines_of_interest: "18-206"

    - path: "src/vector_store/mod.rs"
      description: "Qdrant vector store integration"
      key_structs: "[VectorStore, VectorStoreConfig, SearchResult]"
      lines_of_interest: "55-420"

    - path: "src/indexing/unified.rs"
      description: "Unified indexing pipeline"
      key_structs: "[UnifiedIndexer, IndexStats]"
      lines_of_interest: "64-200+"

    - path: "src/schema.rs"
      description: "Tantivy schemas for indexing"
      key_structs: "[FileSchema, ChunkSchema]"
      lines_of_interest: "11-179"

  test_files:
    - path: "tests/test_hybrid_search.rs"
      description: "Integration tests for hybrid search"
      tests:
        - "test_manual_hybrid_search"
        - "test_incremental_indexing"
        - "test_qdrant_connection"

key_algorithms:

  rrf_merging:
    file: "src/search/mod.rs"
    function: "reciprocal_rank_fusion_with_k"
    lines: "196-263"

    pseudocode: |
      function rrf_merge(vector_results, bm25_results, k, vector_weight, bm25_weight):
        scores = HashMap<ChunkId, RrfScore>()

        // Process vector results
        for (rank, result) in enumerate(vector_results):
          rrf_score = 1.0 / (k + rank + 1)
          scores[result.chunk_id].rrf_score += rrf_score * vector_weight
          scores[result.chunk_id].vector_score = result.score
          scores[result.chunk_id].vector_rank = rank + 1

        // Process BM25 results
        for (rank, result) in enumerate(bm25_results):
          rrf_score = 1.0 / (k + rank + 1)
          scores[result.chunk_id].rrf_score += rrf_score * bm25_weight
          scores[result.chunk_id].bm25_score = result.score
          scores[result.chunk_id].bm25_rank = rank + 1

        // Sort by combined RRF score
        results = scores.values().sort_by(|a, b| b.rrf_score.cmp(a.rrf_score))
        return results

    complexity:
      time: "O(n + m + (n+m)log(n+m))"
      space: "O(n + m)"
      where: "n = vector results, m = BM25 results"

example_usage:
  basic_search:
    code: |
      // Initialize components
      let mut indexer = UnifiedIndexer::new(
          cache_path,
          tantivy_path,
          "http://localhost:6334",
          "my_project",
          384
      ).await?;

      // Index codebase (incremental)
      let stats = indexer.index_directory(project_path).await?;

      // Create hybrid search
      let bm25 = indexer.create_bm25_search()?;
      let hybrid_search = HybridSearch::with_defaults(
          indexer.embedding_generator_cloned(),
          indexer.vector_store_cloned(),
          Some(bm25),
      );

      // Search
      let results = hybrid_search.search("parse arguments", 10).await?;

      // Results include both BM25 and vector scores
      for result in results {
          println!("Score: {:.4}", result.score);
          println!("  BM25: {:?}", result.bm25_score);
          println!("  Vector: {:?}", result.vector_score);
          println!("  Symbol: {}", result.chunk.context.symbol_name);
      }

  custom_configuration:
    code: |
      // Create custom config favoring semantic search
      let config = HybridSearchConfig {
          bm25_weight: 0.3,
          vector_weight: 0.7,
          rrf_k: 60.0,
          candidate_count: 150,
      };

      let hybrid_search = HybridSearch::new(
          embedding_gen,
          vector_store,
          bm25_search,
          config,
      );

  parameter_tuning:
    code: |
      // Define test queries
      let test_queries = vec![
          TestQuery {
              query: "parse command line".to_string(),
              relevant_chunk_ids: vec!["clap_parser".to_string()],
          },
          // ... more queries
      ];

      // Tune RRF k parameter
      let tuner = RRFTuner::new(test_queries);
      let result = tuner.tune_k(&hybrid_search).await?;

      println!("Optimal k: {} (NDCG: {:.4})", result.best_k, result.best_ndcg);

  resilient_search:
    code: |
      // Create resilient wrapper
      let resilient = ResilientHybridSearch::with_defaults(
          Some(bm25_search),
          Some(vector_store),
          Some(embedding_gen),
      );

      // Automatic fallback if components fail
      let results = resilient.search("test query", 10).await?;

      // Check if in fallback mode
      if resilient.is_fallback_mode() {
          println!("Warning: Running in degraded mode");
      }

strengths:
  - "Unified indexing ensures consistency between BM25 and vector stores"
  - "Parallel search execution for low latency"
  - "Transparent result scoring with metadata preservation"
  - "Configurable weighting for different query types"
  - "Automatic fallback for production reliability"
  - "Parameter tuning framework with multiple evaluation metrics"
  - "Incremental indexing reduces reindex overhead"
  - "Rich context preservation (docstrings, imports, call graphs)"

potential_improvements:
  - "Query-adaptive weighting (dynamic based on query characteristics)"
  - "Learned weight optimization (ML-based parameter learning)"
  - "Result re-ranking with additional signals"
  - "Query expansion for better recall"
  - "Caching of frequent queries"
  - "A/B testing framework for configuration comparison"

dependencies:
  tantivy: "Full-text search library (BM25)"
  qdrant_client: "Qdrant vector database client"
  fastembed: "Fast embedding generation (ONNX runtime)"
  tree_sitter: "Rust code parsing"
  tokio: "Async runtime for parallel execution"

configuration_files:
  environment_variables:
    QDRANT_URL:
      default: "http://localhost:6334"
      description: "Qdrant gRPC endpoint"

  runtime_config:
    location: "Passed to UnifiedIndexer and HybridSearch constructors"
    no_config_file: "All configuration is programmatic"

notes:
  - "Port 6334 is Qdrant gRPC (not 6333 HTTP)"
  - "Collection names are sanitized (alphanumeric + underscore only)"
  - "RRF k=60 is standard from research literature"
  - "Equal weights (0.5/0.5) work well for general queries"
  - "Incremental indexing uses SHA-256 file hashing"
  - "Embeddings cached in .fastembed_cache/"

references:
  rrf_paper: "https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf"
  tantivy_docs: "https://docs.rs/tantivy/"
  qdrant_docs: "https://qdrant.tech/documentation/"
  fastembed_docs: "https://github.com/Anush008/fastembed-rs"
