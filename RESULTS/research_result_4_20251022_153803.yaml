comparison_report:
  title: "Qdrant vs Milvus/Zilliz Cloud Integration Comparison"
  subtitle: "file-search-mcp (Qdrant) vs claude-context (Milvus)"
  
  executive_summary:
    file_search_mcp:
      language: "Rust"
      vector_db: "Qdrant"
      deployment: "Local (self-hosted)"
      primary_use_case: "Rust code search with MCP tools"
      
    claude_context:
      language: "TypeScript/JavaScript"
      vector_db: "Milvus/Zilliz Cloud"
      deployment: "Both local and cloud"
      primary_use_case: "Multi-language code context for Claude"

  collection_management:
    
    qdrant_file_search_mcp:
      collection_creation:
        location: "src/vector_store/mod.rs:97-176"
        api: "CreateCollection proto message"
        approach: "Explicit creation with HNSW configuration"
        schema_type: "Schema-free with payload storage"
        
      collection_naming:
        pattern: "code_chunks_{project_name}"
        sanitization: "Replace hyphens/spaces with underscores"
        example: "code_chunks_rust_code_mcp"
        alternative: "SHA-256 hash of directory path (8 chars)"
        
      vector_configuration:
        dimensions: 384
        distance_metric: "Cosine"
        embedding_model: "all-MiniLM-L6-v2"
        
      hnsw_parameters:
        small_codebase:
          threshold: "< 100k LOC"
          m: 16
          ef_construct: 100
          ef: 128
          indexing_threads: 8
          
        medium_codebase:
          threshold: "100k - 1M LOC"
          m: 16
          ef_construct: 150
          ef: 128
          indexing_threads: 12
          
        large_codebase:
          threshold: "> 1M LOC"
          m: 32
          ef_construct: 200
          ef: 256
          indexing_threads: 16
          
      optimization_config:
        location: "src/vector_store/config.rs:10-129"
        features:
          - "Auto-tuning based on codebase size"
          - "Dynamic HNSW parameter adjustment"
          - "Memmap threshold configuration"
          - "Indexing thread control"
        
      collection_operations:
        check_exists: "list_collections() API"
        delete_collection: "delete_collection() method"
        clear_collection: "DeletePoints with empty filter"
        count_points: "collection_info().points_count"
        
    milvus_claude_context:
      collection_creation:
        api: "MilvusClient.create_collection() or createCollection()"
        approach: "Schema-based with field definitions"
        schema_type: "Explicit field schema with types"
        
      field_schema:
        primary_key:
          name: "chunk_id or book_id"
          type: "Int64"
          auto_id: false
          
        vector_field:
          name: "text_dense"
          type: "FloatVector"
          dimensions: 768
          note: "Depends on embedding model"
          
        metadata_fields:
          text:
            type: "VarChar"
            max_length: 2000
            enable_analyzer: true
            
          sparse_vector:
            name: "text_sparse"
            type: "SparseFloatVector"
            note: "For BM25 search"
            
        dynamic_fields:
          enabled: true
          storage: "Reserved $meta field"
          
      collection_configuration:
        shard_number: "1 shard per 200M entities (guideline)"
        mmap_enabled: "Reduces memory footprint"
        ttl_seconds: "Auto-delete after specified time"
        consistency_level: "Strong/Bounded/Session/Eventually"
        
      index_configuration:
        dense_vector:
          field: "text_dense"
          index_type: "AUTOINDEX"
          metric_type: "COSINE"
          
        sparse_vector:
          field: "text_sparse"
          index_type: "SPARSE_INVERTED_INDEX"
          metric_type: "BM25"
          
      abstraction_layer:
        interface: "VectorDatabase interface"
        implementation: "MilvusVectorDatabase class"
        high_level_api: "Context class"
        
      collection_operations:
        check_exists: "collectionExists() method"
        create: "createCollection() with schema"
        drop: "dropCollection() method"
        describe: "describeCollection() for metadata"

  point_vector_insertion:
    
    qdrant_file_search_mcp:
      insertion_method:
        location: "src/vector_store/mod.rs:178-229"
        api: "upsert_points()"
        batch_size: 100
        
      point_structure:
        id: "UUID as string (ChunkId)"
        vectors: "Vec<f32> with 384 dimensions"
        payload: "Full CodeChunk as JSON"
        
      payload_schema:
        storage_format: "HashMap<String, qdrant::Value>"
        serialization: "serde_json to nested JSON strings"
        full_chunk_data:
          - "id: ChunkId"
          - "content: String"
          - "context.file_path: PathBuf"
          - "context.module_path: Vec<String>"
          - "context.symbol_name: String"
          - "context.symbol_kind: String"
          - "context.docstring: Option<String>"
          - "context.imports: Vec<String>"
          - "context.outgoing_calls: Vec<String>"
          - "context.line_start: usize"
          - "context.line_end: usize"
          - "overlap_prev: Option<String>"
          - "overlap_next: Option<String>"
          
      indexing_pipeline:
        entry_point: "src/indexing/unified.rs:266-292"
        steps:
          1: "Parse file with TreeSitter"
          2: "Chunk code by symbols (functions/classes/structs)"
          3: "Generate embeddings in batch"
          4: "Index to Tantivy (BM25)"
          5: "Upsert to Qdrant (vectors)"
          
      batch_processing:
        embedding_generation: "embed_batch() for efficiency"
        insertion_batching: "100 points per upsert"
        error_handling: "Per-batch error propagation"
        
    milvus_claude_context:
      insertion_method:
        api: "client.insert() or milvusClient.insert()"
        format: "Array of entity objects"
        
      entity_structure:
        python:
          example: |
            {
              "id": 0,
              "text": "Function implementation",
              "text_dense": [0.358, -0.602, ...],  # 768-dim
              "text_sparse": {...},  # BM25 vector
              "file_path": "/src/search.py",
              "start_line": 10,
              "end_line": 25
            }
            
        typescript:
          example: |
            {
              id: 0,
              text: "Function implementation",
              text_dense: [0.358, -0.602, ...],
              file_path: "/src/search.ts",
              start_line: 10
            }
            
      indexing_abstraction:
        high_level_api: "context.indexCodebase(path, callback)"
        automatic_steps:
          1: "Scan files"
          2: "AST-based code chunking"
          3: "Generate embeddings"
          4: "Insert into Milvus"
          5: "Update Merkle tree for incremental sync"
          
      chunking_strategy:
        primary: "AST-based code splitting"
        parser: "Tree-sitter for multiple languages"
        chunks: "Functions, classes, methods with context"
        fallback: "Character-based if parsing fails"
        
      batch_processing:
        embedding: "Batch embedding generation"
        insertion: "Array of entities per insert() call"
        progress_tracking: "Callback with phase/percentage"

  similarity_search_apis:
    
    qdrant_file_search_mcp:
      vector_search:
        location: "src/vector_store/mod.rs:231-291"
        method: "search_points()"
        input: "Embedding (Vec<f32>)"
        output: "Vec<SearchResult>"
        
      search_parameters:
        collection_name: "String"
        vector: "Query embedding"
        limit: "u64 (number of results)"
        with_payload: "true (include full chunk data)"
        
      hybrid_search:
        location: "src/search/mod.rs:129-180"
        approach: "BM25 + Vector with RRF"
        parallel_execution: "tokio::join! for concurrent search"
        
      rrf_algorithm:
        formula: "score(item) = sum(1 / (k + rank_i))"
        default_k: 60.0
        weights:
          bm25_weight: 0.5
          vector_weight: 0.5
        candidate_count: 100
        
      search_modes:
        hybrid_search:
          method: "search(query, limit)"
          combines: "BM25 + Vector"
          reranking: "Reciprocal Rank Fusion"
          
        vector_only:
          method: "vector_only_search(query, limit)"
          uses: "Pure semantic similarity"
          
        custom_k:
          method: "search_with_k(query, limit, rrf_k)"
          purpose: "RRF parameter tuning"
          
      result_structure:
        fields:
          - "chunk_id: ChunkId"
          - "score: f32 (combined RRF score)"
          - "bm25_score: Option<f32>"
          - "vector_score: Option<f32>"
          - "bm25_rank: Option<usize>"
          - "vector_rank: Option<usize>"
          - "chunk: CodeChunk (full data)"
          
    milvus_claude_context:
      basic_search:
        python_api: "collection.search()"
        node_api: "milvusClient.search()"
        
      search_parameters:
        collection_name: "String"
        vector: "Query embedding array"
        anns_field: "Field name (e.g., 'text_dense')"
        limit: "Number of results"
        expr: "Filter expression (optional)"
        output_fields: "Array of field names to return"
        consistency_level: "Strong/Bounded/Session/Eventually"
        
      hybrid_search:
        approach: "BM25 + Dense vector with RRF"
        api: "client.hybrid_search()"
        
      hybrid_implementation:
        dense_request:
          field: "text_dense"
          metric: "COSINE"
          limit: "limit * 2 (oversampling)"
          
        sparse_request:
          field: "text_sparse"
          metric: "BM25"
          params:
            drop_ratio_build: 0.0
          limit: "limit * 2"
          
        ranker: "RRFRanker()"
        weights:
          dense: 0.7
          sparse: 0.3
          
      high_level_api:
        method: "context.semanticSearch(projectPath, query, limit)"
        steps:
          1: "Generate query embedding"
          2: "Perform hybrid search (dense + BM25)"
          3: "Rerank with RRF"
          4: "Return top results"
          
      result_structure:
        fields:
          - "content: code snippet"
          - "relativePath: file path"
          - "startLine: number"
          - "endLine: number"
          - "language: programming language"
          - "score: similarity score"
          - "fileExtension: file type"
          
      metric_types:
        COSINE:
          behavior: "Higher = more similar"
          range: "[-1, 1]"
          use_case: "Semantic similarity (normalized)"
          
        L2:
          behavior: "Lower = more similar"
          range: "[0, ∞)"
          use_case: "Euclidean distance"
          
        IP:
          behavior: "Higher = more similar"
          range: "[-1, 1]"
          use_case: "Inner product"
          
        BM25:
          behavior: "Higher = more similar"
          range: "[0, ∞)"
          use_case: "Keyword matching"

  database_configuration:
    
    qdrant_file_search_mcp:
      connection_setup:
        location: "src/vector_store/mod.rs:72-94"
        api: "QdrantClient::from_url()"
        
      default_configuration:
        url: "http://localhost:6334"
        port_type: "gRPC"
        collection_name: "code_chunks_{project_name}"
        vector_size: 384
        
      environment_variables:
        QDRANT_URL:
          default: "http://localhost:6334"
          usage: "Override default connection URL"
          locations:
            - "src/tools/search_tool.rs:260-261"
            - "src/tools/health_tool.rs:70-71"
            
      client_initialization:
        method: "new_with_optimization(config, optimized_config)"
        steps:
          1: "Create QdrantClient from URL"
          2: "Wrap in Arc<> for thread safety"
          3: "Create or verify collection exists"
          4: "Apply HNSW optimization config"
          
      deployment_model:
        type: "Local self-hosted only"
        docker: "Recommended via Docker Compose"
        port: "6334 (gRPC) / 6333 (REST)"
        storage: "Local filesystem (./storage/)"
        
      connection_string_examples:
        local: "http://localhost:6334"
        custom_port: "http://localhost:8080"
        remote: "http://192.168.1.100:6334"
        
    milvus_claude_context:
      connection_setup:
        python_api: "MilvusClient(uri, token, db_name)"
        node_api: "new MilvusClient({address, token})"
        
      local_milvus:
        configuration:
          uri: "http://localhost:19530"
          token: "root:Milvus"
          db_name: "default"
          
        ports:
          grpc: 19530
          rest: 19530
          
        deployment:
          - "Docker: docker-compose.yml"
          - "Kubernetes: Helm charts"
          - "Standalone: Binary installation"
          
      zilliz_cloud:
        configuration:
          uri: "https://in03-xxx.api.gcp-us-west1.zillizcloud.com:443"
          token: "db_xxxxxx:your-api-key"
          db_name: "default"
          
        features:
          - "Fully managed SaaS"
          - "Auto-scaling"
          - "Global availability"
          - "50-70% faster than local"
          
      environment_variables:
        MILVUS_ADDRESS:
          local_example: "http://localhost:19530"
          cloud_example: "https://in03-xxx.api.gcp-us-west1.zillizcloud.com:443"
          
        MILVUS_TOKEN:
          local_example: "root:Milvus"
          cloud_example: "db_xxxxxx:your-api-key"
          
      connection_patterns:
        simple:
          python: "MilvusClient('http://localhost:19530')"
          
        with_auth:
          python: "MilvusClient(uri=url, token='user:pass', db_name='default')"
          
        separate_credentials:
          python: "MilvusClient(uri=url, user='root', password='Milvus')"
          
      deployment_comparison:
        local_milvus:
          pros:
            - "Full control"
            - "No external dependencies"
            - "Infrastructure cost only"
          cons:
            - "Manual scaling"
            - "Self-managed monitoring"
            - "Limited to hardware"
            
        zilliz_cloud:
          pros:
            - "Faster performance (50-70%)"
            - "Auto-scaling"
            - "Enterprise security (SOC2, GDPR, HIPAA)"
            - "Global CDN"
          cons:
            - "Usage-based pricing"
            - "Network latency to cloud"
            - "External dependency"

  connection_handling:
    
    qdrant_file_search_mcp:
      client_management:
        location: "src/vector_store/mod.rs:54-60"
        structure: "Arc<QdrantClient>"
        thread_safety: "Arc provides shared ownership"
        
      pooling_strategy:
        approach: "Single client wrapped in Arc"
        cloning: "Cheap clone (Arc::clone)"
        sharing: "Shared across concurrent operations"
        
      lifecycle:
        initialization: "Once during VectorStore::new()"
        persistence: "Lives for entire indexer lifetime"
        reuse: "All operations use same client"
        
      concurrency:
        parallelism: "Multiple operations can share client"
        safety: "Arc ensures thread-safe access"
        indexing: "Parallel file indexing with shared client"
        searching: "Concurrent searches supported"
        
      error_handling:
        connection_failure: "Propagate errors to caller"
        retry_logic: "No automatic retry (user handles)"
        timeout: "No explicit timeout configured"
        
    milvus_claude_context:
      connection_pooling:
        python_sdk: "Automatic connection pool (v0.9.0+)"
        pool_size: "No upper limit"
        thread_safety: "Built-in thread-safe operations"
        reconnection: "Automatic on failure"
        
      client_lifecycle:
        pattern: "Singleton or dependency injection"
        example: |
          class DatabaseManager:
              _instance = None
              _client = None
              
              @classmethod
              def get_client(cls):
                  if cls._client is None:
                      cls._client = MilvusClient(
                          uri=os.getenv("MILVUS_ADDRESS"),
                          token=os.getenv("MILVUS_TOKEN"),
                          timeout=30
                      )
                  return cls._client
                  
      configuration_parameters:
        timeout: "Operation timeout (default: 30s)"
        max_retries: "Connection retry attempts (3)"
        log_level: "debug/info/warn/error"
        
      node_configuration:
        typescript: |
          new MilvusClient({
            address: 'localhost:19530',
            username: 'root',
            password: 'Milvus',
            logLevel: 'info',
            maxRetries: 3,
            timeout: 30000
          })
          
      best_practices:
        - "Reuse MilvusClient instances"
        - "Use singleton pattern for connection"
        - "Configure appropriate timeouts"
        - "Enable debug logging in development"

  database_abstraction_layers:
    
    qdrant_file_search_mcp:
      layer_1_vector_store:
        location: "src/vector_store/mod.rs:54-420"
        struct: "VectorStore"
        purpose: "Primary Qdrant abstraction"
        
        core_operations:
          - "upsert_chunks(): Batch insert"
          - "search(): Vector similarity search"
          - "delete_chunks(): Delete by IDs"
          - "delete_by_file_path(): Filter-based deletion"
          - "count(): Get point count"
          - "clear_collection(): Remove all points"
          - "delete_collection(): Drop collection"
          
      layer_2_vector_search:
        location: "src/search/mod.rs:62-92"
        struct: "VectorSearch"
        purpose: "Query embedding + search"
        
        components:
          embedding_generator: "Converts text to vectors"
          vector_store: "Qdrant client wrapper"
          
        flow: "query → embedding → search → results"
        
      layer_3_hybrid_search:
        location: "src/search/mod.rs:94-354"
        struct: "HybridSearch"
        purpose: "BM25 + Vector with RRF"
        
        components:
          vector_search: "VectorSearch instance"
          bm25_search: "Optional<Bm25Search>"
          config: "HybridSearchConfig"
          
        coordination:
          - "Parallel vector + BM25 search"
          - "RRF score merging"
          - "Result deduplication"
          
      layer_4_unified_indexer:
        location: "src/indexing/unified.rs:63-360"
        struct: "UnifiedIndexer"
        purpose: "Complete indexing pipeline"
        
        integrations:
          - "TreeSitter parser"
          - "Code chunker"
          - "Embedding generator"
          - "Vector store (Qdrant)"
          - "BM25 index (Tantivy)"
          
        pipeline: "parse → chunk → embed → index (both stores)"
        
      layer_5_incremental_indexer:
        location: "src/indexing/incremental.rs:43-132"
        struct: "IncrementalIndexer"
        purpose: "Change detection + selective reindexing"
        
        features:
          - "Merkle tree for file change tracking"
          - "Selective reindexing"
          - "Sub-10ms no-change detection"
          
      layer_6_mcp_tools:
        search_tool: "src/tools/search_tool.rs"
        index_tool: "src/tools/index_tool.rs"
        health_tool: "src/tools/health_tool.rs"
        
        purpose: "MCP protocol integration"
        
    milvus_claude_context:
      layer_1_vector_database_interface:
        definition: "VectorDatabase interface"
        language: "TypeScript"
        
        operations:
          - "createCollection(name, schema)"
          - "collectionExists(name)"
          - "insert(collectionName, data)"
          - "delete(collectionName, filter)"
          - "search(params)"
          - "hybridSearch(params)"
          - "connect()"
          - "disconnect()"
          
      layer_2_milvus_implementation:
        class: "MilvusVectorDatabase"
        implements: "VectorDatabase interface"
        
        responsibilities:
          - "Milvus client management"
          - "Collection operations"
          - "Hybrid search with RRF"
          - "Connection handling"
          
      layer_3_context_api:
        class: "Context"
        purpose: "High-level semantic code search"
        
        components:
          embedding: "EmbeddingProvider (OpenAI/Voyage/Gemini/Ollama)"
          vector_database: "VectorDatabase (Milvus)"
          code_splitter: "CodeSplitter (AST-based)"
          
        main_methods:
          index_codebase:
            signature: "async indexCodebase(path, callback)"
            steps:
              1: "Scan files"
              2: "Chunk code using AST"
              3: "Generate embeddings"
              4: "Insert into Milvus"
              5: "Update Merkle tree"
              
          semantic_search:
            signature: "async semanticSearch(projectPath, query, limit)"
            steps:
              1: "Generate query embedding"
              2: "Hybrid search (dense + BM25)"
              3: "Rerank with RRF"
              4: "Return top results"
              
      layer_4_embedding_abstraction:
        interface: "EmbeddingProvider"
        
        implementations:
          OpenAIEmbedding:
            model: "text-embedding-3-small"
            dimensions: 1536
            
          VoyageAIEmbedding:
            model: "voyage-code-2"
            dimensions: 1536
            
          GeminiEmbedding:
            model: "text-embedding-004"
            dimensions: 768
            
          OllamaEmbedding:
            model: "nomic-embed-text"
            dimensions: 768
            
      layer_5_mcp_server:
        package: "@zilliz/claude-context-mcp"
        purpose: "MCP protocol server"
        
        tools:
          - "index_codebase: Index project"
          - "semantic_search: Search code"
          - "list_projects: Show indexed projects"
          
      multi_tenancy:
        pattern: "Collection per project"
        naming: "code_chunks_{sanitized_project_name}"
        isolation: "Separate collections for each codebase"

  key_differences_summary:
    
    language_ecosystem:
      file_search_mcp: "Rust (compile-time safety)"
      claude_context: "TypeScript/JavaScript (npm ecosystem)"
      
    deployment_flexibility:
      file_search_mcp:
        options: "Local only (self-hosted Qdrant)"
        complexity: "Docker/Kubernetes setup required"
        
      claude_context:
        options: "Local Milvus OR Zilliz Cloud"
        complexity: "Simple config switch for cloud"
        
    schema_approach:
      file_search_mcp:
        type: "Schema-free payloads"
        storage: "Full JSON in payload HashMap"
        flexibility: "Store arbitrary data"
        
      claude_context:
        type: "Explicit field schema"
        storage: "Typed fields + dynamic $meta"
        flexibility: "Structured with dynamic extension"
        
    collection_optimization:
      file_search_mcp:
        feature: "Auto-tuning HNSW parameters"
        basis: "Codebase size (LOC)"
        tiers: "Small/Medium/Large (< 100k / 100k-1M / > 1M)"
        
      claude_context:
        feature: "AUTOINDEX"
        basis: "Milvus auto-optimization"
        config: "Manual index type selection"
        
    hybrid_search:
      file_search_mcp:
        bm25_engine: "Tantivy (separate Rust crate)"
        vector_engine: "Qdrant"
        fusion: "Custom RRF implementation"
        parallelism: "tokio::join! for async"
        
      claude_context:
        bm25_engine: "Milvus built-in sparse vectors"
        vector_engine: "Milvus dense vectors"
        fusion: "Milvus RRFRanker"
        parallelism: "Milvus internal"
        
    connection_management:
      file_search_mcp:
        pattern: "Arc<QdrantClient> (manual sharing)"
        pooling: "Single client reused"
        
      claude_context:
        pattern: "Automatic connection pool"
        pooling: "Built-in by pymilvus/milvus2-sdk-node"
        
    incremental_indexing:
      file_search_mcp:
        implementation: "Merkle tree in Rust"
        speed: "< 10ms for no-change detection"
        location: "src/indexing/incremental.rs"
        
      claude_context:
        implementation: "Merkle tree in TypeScript"
        speed: "Fast change detection"
        integration: "Built into Context class"
        
    cloud_readiness:
      file_search_mcp:
        status: "Local-only architecture"
        migration: "Would require significant refactoring"
        
      claude_context:
        status: "Cloud-first design"
        migration: "Single env variable change"
        
    abstraction_depth:
      file_search_mcp:
        layers: 6
        detail: "More granular control"
        complexity: "Higher learning curve"
        
      claude_context:
        layers: 5
        detail: "Higher-level API"
        complexity: "Easier to use"

  performance_characteristics:
    
    file_search_mcp:
      batch_insertion:
        size: "100 points per upsert"
        location: "src/vector_store/mod.rs:218"
        
      parallel_operations:
        search: "Vector + BM25 concurrent (tokio::join!)"
        indexing: "Parallel file processing"
        
      optimization_features:
        - "HNSW auto-tuning by codebase size"
        - "Batch embedding generation"
        - "Arc-based client pooling"
        - "Incremental indexing (Merkle tree)"
        
      memory_efficiency:
        memmap_threshold:
          small: "50,000 points"
          large: "30,000 points (aggressive)"
          
    claude_context:
      performance_gains:
        token_reduction: "~40% fewer tokens"
        cost_savings: "Significant for API-based LLMs"
        
      cloud_advantage:
        zilliz_improvement: "50-70% faster than local"
        scaling: "Auto-scaling based on load"
        
      optimization_features:
        - "Built-in AUTOINDEX"
        - "Incremental updates (Merkle tree)"
        - "Parallel processing"
        - "Result caching"
        - "Partition-scoped search"

  use_case_recommendations:
    
    choose_file_search_mcp_qdrant_when:
      - "Building Rust-native applications"
      - "Need fine-grained control over vector operations"
      - "Preference for self-hosted solutions"
      - "Working exclusively with Rust codebases"
      - "Want compile-time safety guarantees"
      - "Already have Qdrant infrastructure"
      
    choose_claude_context_milvus_when:
      - "Building cross-language code search"
      - "Need cloud deployment flexibility"
      - "Want production-ready managed service"
      - "Require enterprise security compliance"
      - "Need global availability"
      - "Prefer TypeScript/JavaScript ecosystem"
      - "Want built-in hybrid search"
      - "Need faster time to production"

  technical_architecture:
    
    file_search_mcp:
      stack:
        language: "Rust"
        vector_db: "Qdrant (gRPC)"
        bm25_engine: "Tantivy"
        embedding: "rust-bert (all-MiniLM-L6-v2)"
        parser: "tree-sitter"
        async_runtime: "tokio"
        
      dependencies:
        - "qdrant-client: Qdrant Rust client"
        - "tantivy: BM25 search engine"
        - "rust-bert: Local embedding generation"
        - "tree-sitter: Code parsing"
        - "serde: Serialization"
        
    claude_context:
      stack:
        language: "TypeScript/JavaScript"
        vector_db: "Milvus/Zilliz Cloud"
        bm25_engine: "Milvus sparse vectors"
        embedding: "OpenAI/Voyage/Gemini/Ollama APIs"
        parser: "tree-sitter"
        
      dependencies:
        - "@zilliz/milvus2-sdk-node: Milvus client"
        - "pymilvus: Python Milvus client"
        - "openai: Embedding API"
        - "@zilliz/claude-context-core: Core library"
        - "@zilliz/claude-context-mcp: MCP server"

  code_references:
    
    file_search_mcp_key_files:
      vector_store: "src/vector_store/mod.rs (420 lines)"
      config: "src/vector_store/config.rs (210 lines)"
      search: "src/search/mod.rs (550 lines)"
      hybrid: "src/search/mod.rs:94-354"
      unified_indexer: "src/indexing/unified.rs (360 lines)"
      incremental: "src/indexing/incremental.rs (132 lines)"
      search_tool: "src/tools/search_tool.rs"
      
    claude_context_resources:
      github: "https://github.com/zilliztech/claude-context"
      npm_core: "@zilliz/claude-context-core"
      npm_mcp: "@zilliz/claude-context-mcp"
      docs_milvus: "https://milvus.io/docs"
      docs_zilliz: "https://zilliz.com/cloud"

  conclusion:
    summary: |
      Both integrations provide robust vector database solutions for semantic code search,
      but with different architectural philosophies:
      
      - file-search-mcp (Qdrant): Rust-first, self-hosted, fine-grained control
      - claude-context (Milvus): Cloud-ready, multi-language, rapid deployment
      
      The choice depends on deployment requirements, language preferences, and whether
      cloud flexibility or self-hosted control is prioritized.