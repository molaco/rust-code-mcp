# Complete System Comparison: rust-code-mcp vs claude-context

**Analysis Date:** 2025-10-19
**Document Type:** Comprehensive Technical Comparison
**Author:** Research Analysis Team
**Version:** 2.0 (Combined Analysis)

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [System Architecture Overview](#system-architecture-overview)
3. [Code Chunking Strategies](#code-chunking-strategies)
4. [MCP Tool Comparison](#mcp-tool-comparison)
5. [Performance Characteristics](#performance-characteristics)
6. [Production Readiness](#production-readiness)
7. [Recommendations](#recommendations)

---

# Executive Summary

## Overview

This document provides a comprehensive comparison between **rust-code-mcp** (8-tool MCP server for Rust code intelligence) and **claude-context** (4-tool multi-language semantic code search). The analysis covers architecture, chunking strategies, tool capabilities, performance, and production readiness.

## Key Findings

### System Philosophy

**rust-code-mcp:**
- **Approach:** Privacy-first, local-only code intelligence
- **Focus:** Deep Rust-specific analysis with rich metadata enrichment
- **Architecture:** Symbol-based chunking with complete semantic units
- **Privacy:** 100% local processing, zero external API calls
- **Cost:** $0 (no API fees, no cloud services)

**claude-context:**
- **Approach:** Cloud-powered, production-ready semantic search
- **Focus:** Multi-language breadth with robust error handling
- **Architecture:** Character-bounded AST chunking with graceful fallbacks
- **Privacy:** Code sent to external APIs (OpenAI, Milvus)
- **Cost:** $$$ (API fees: ~$0.00013 per 1K tokens)

### Critical Differences Summary

| Dimension | rust-code-mcp | claude-context |
|-----------|---------------|----------------|
| **Tool Count** | 8 specialized tools | 4 focused tools |
| **Languages** | Rust only | 20+ languages |
| **Indexing** | On-demand, synchronous | Background, asynchronous |
| **Change Detection** | SHA-256 (seconds) | Merkle DAG (milliseconds) |
| **Embeddings** | Local (384d) | API (3072d) |
| **Vector DB** | Qdrant (local) | Milvus/Zilliz (cloud) |
| **Chunking** | Symbol-based (variable) | Character-bounded (2500 chars) |
| **Context Enrichment** | Very high (imports, calls, docs) | Low (path, language only) |
| **Fallback** | None | Dual (AST â†’ LangChain) |
| **Privacy** | Complete | Compromised |
| **Cost** | Zero | Recurring |
| **Maturity** | Phase 7 - Testing | Production-deployed |

### Complementary Strengths

The two systems are highly complementary:
- **rust-code-mcp's** rich context enrichment could enhance **claude-context's** multi-language chunks
- **claude-context's** fallback robustness could make **rust-code-mcp** production-ready
- A hybrid combining both approaches would be optimal

---

# System Architecture Overview

## rust-code-mcp Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Server (Rust)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  8 Tools:                                                â”‚
â”‚  â€¢ search (BM25)                 â€¢ find_definition       â”‚
â”‚  â€¢ get_similar_code (vector)     â€¢ find_references       â”‚
â”‚  â€¢ read_file_content             â€¢ get_dependencies      â”‚
â”‚  â€¢ get_call_graph                â€¢ analyze_complexity    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Tantivy    â”‚  â”‚   Qdrant     â”‚  â”‚ tree-sitter  â”‚
â”‚  (BM25 Index)â”‚  â”‚ (Vectors)    â”‚  â”‚  (AST Parse) â”‚
â”‚              â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ File-level   â”‚  â”‚ fastembed    â”‚  â”‚ Rust-only    â”‚
â”‚ Chunk-level  â”‚  â”‚ 384d local   â”‚  â”‚ Deep parsing â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Local Storage (~/.local/share/)                  â”‚
â”‚  â€¢ Tantivy index/                                        â”‚
â”‚  â€¢ sled metadata cache/                                  â”‚
â”‚  â€¢ Qdrant storage/                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

**Parser (src/parser/mod.rs - 808 lines)**
- `RustParser` with tree-sitter-rust
- 9 symbol extractors (function, struct, trait, impl, enum, module, const, static, type_alias)
- Call graph builder (`call_graph.rs`)
- Import extractor (`imports.rs`)
- Type reference tracker (`type_references.rs`)

**Chunker (src/chunker/mod.rs - 486 lines)**
- Symbol-based semantic chunking
- One symbol = one chunk (variable size)
- Rich context enrichment with Anthropic's contextual retrieval pattern
- 20% line-based overlap between chunks

**Embeddings (src/embeddings/mod.rs)**
- Local inference via fastembed-rs
- Model: all-MiniLM-L6-v2 (384 dimensions)
- Format: Structured metadata + code

**Search (src/search/mod.rs)**
- Hybrid search with RRF (Reciprocal Rank Fusion)
- BM25: Tantivy on file-level and chunk-level
- Vector: Qdrant wrapper
- Configurable fusion weights

**Tools (src/tools/search_tool.rs - 1,095 lines)**
- 8 MCP tools with CallToolResult interface
- On-demand indexing with SHA-256 change detection
- Binary file detection heuristics

## claude-context Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MCP Server (TypeScript/Node.js)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  4 Tools:                                                â”‚
â”‚  â€¢ index_codebase         â€¢ search_code                  â”‚
â”‚  â€¢ clear_index            â€¢ get_indexing_status          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Milvus/    â”‚  â”‚   OpenAI     â”‚  â”‚ tree-sitter  â”‚
â”‚   Zilliz     â”‚  â”‚   API        â”‚  â”‚ (AST Split)  â”‚
â”‚   (Cloud)    â”‚  â”‚              â”‚  â”‚              â”‚
â”‚ Hybrid BM25+ â”‚  â”‚ 3072d        â”‚  â”‚ 10 languages â”‚
â”‚ Dense Vector â”‚  â”‚ embeddings   â”‚  â”‚ + LangChain  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Local Storage (~/.context/)                      â”‚
â”‚  â€¢ merkle/ (DAG snapshots)                               â”‚
â”‚  â€¢ .env (global config)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

**Splitter (packages/core/src/splitter/)**
- `AstCodeSplitter` (11,235 bytes): tree-sitter based
  - 10 languages (JS, TS, Python, Java, C++, C, Go, Rust, C#, Scala)
  - 2,500 character chunks (default)
  - 300 character overlap
- `LangChainCodeSplitter` (4,792 bytes): fallback
  - RecursiveCharacterTextSplitter
  - 1,000 character chunks, 200 overlap
  - 20+ languages

**Change Detection**
- Merkle DAG (tree-based hashing)
- Phase 1: Root hash comparison (milliseconds)
- Phase 2: Selective tree traversal (changed subtrees only)
- 60-80% skip rate on typical git workflows

**Orchestration (packages/core/src/context.ts - 49,276 bytes)**
- Async background indexing
- Progress tracking with callbacks
- Multi-codebase management
- Graceful error handling with dual fallback

**Embeddings**
- OpenAI `text-embedding-3-large` (3072d) - primary
- VoyageAI `voyage-code-3` (specialized for code)
- Ollama (local models)
- Gemini (alternative)

---

# Code Chunking Strategies

## Chunking Philosophy Comparison

### rust-code-mcp: Pure Semantic Chunking

**Principle:** One symbol = one chunk

**Strategy:**
- Extract complete semantic units via tree-sitter AST
- Symbol types: function, struct, trait, impl, enum, module, const, static, type_alias
- Natural symbol boundaries (variable size, unbounded)
- Rich context enrichment (Anthropic contextual retrieval pattern)

**Chunk Structure:**
```rust
pub struct CodeChunk {
    pub id: ChunkId,              // UUID v4
    pub content: String,          // Full symbol source code
    pub context: ChunkContext,    // Rich metadata
    pub overlap_prev: Option<String>,  // 20% overlap
    pub overlap_next: Option<String>,  // 20% overlap
}

pub struct ChunkContext {
    pub file_path: PathBuf,
    pub line_range: (usize, usize),
    pub module_path: String,      // crate::module::submodule
    pub symbol_name: String,
    pub symbol_kind: SymbolKind,
    pub docstring: Option<String>,
    pub imports: Vec<String>,     // Top 5
    pub calls: Vec<String>,       // Top 5 outgoing calls
}
```

**Format for Embedding:**
```rust
// File: src/parser/mod.rs
// Location: lines 130-145
// Module: crate::parser
// Symbol: parse_file (function)
// Purpose: Parse a Rust source file and extract symbols
// Imports: std::fs, std::path::Path, tree_sitter::Parser
// Calls: fs::read_to_string, parse_source

pub fn parse_file(&mut self, path: &Path) -> Result<Vec<Symbol>, Box<dyn std::error::Error>> {
    let source = fs::read_to_string(path)?;
    self.parse_source(&source)
}
```

**Size Characteristics:**
- Small const: 1-2 lines
- Simple function: 5-20 lines
- Complex impl: 50-200+ lines
- Large module: Potentially entire file

**Overlap Method:**
- Line-based (20% default)
- Take first N lines of next symbol
- Take last N lines of previous symbol
- Maintains context across symbol boundaries

### claude-context: Bounded Semantic Chunking

**Principle:** Extract AST nodes within character limits

**Strategy:**
- Character-bounded (2,500 chars default for AST, 1,000 for LangChain)
- AST-guided splitting (function/class/method boundaries)
- Automatic fallback to character-based if AST fails
- Minimal metadata enrichment

**Chunk Structure:**
```typescript
interface CodeChunk {
  content: string;        // Raw code text
  language: string;       // Detected language
  filePath: string;       // Source file path
  metadata: {             // Additional context
    lines?: string;       // Estimated line range
    [key: string]: any;
  };
}
```

**Workflow:**
1. **Parse:** `Parser.parse(code)` â†’ AST tree
2. **Extract:** Traverse nodes, match splittable types (function_declaration, class_declaration, etc.)
3. **Refine:** If chunk > chunk_size, split by lines (`refineChunks()`)
4. **Overlap:** Append last 300 characters from previous chunk (`addOverlap()`)
5. **Return:** `CodeChunk[]` with metadata

**Size Characteristics:**
- Typical: ~50-100 lines (varies by code density)
- Maximum: Never exceeds 2,500 characters
- Refined: Oversized chunks split by `refineChunks()`

**Overlap Method:**
- Character-based (300 chars default)
- Append last 300 characters from previous chunk
- Smooth context transition

## Chunking Comparison Table

| Aspect | rust-code-mcp | claude-context |
|--------|---------------|----------------|
| **Unit** | Complete symbol | AST node or character block |
| **Size Strategy** | Natural boundaries (unbounded) | Character-bounded (2,500 max) |
| **Size Range** | 1 line to 500+ lines | Up to ~100 lines |
| **Overlap Type** | Line-based (20%) | Character-based (300 chars) |
| **Metadata Richness** | Very high (10+ fields) | Low (3 fields) |
| **Semantic Completeness** | 100% guaranteed | Best-effort (may split large functions) |
| **Size Predictability** | Low (highly variable) | High (bounded) |
| **Context Injection** | Explicit (formatted prefix) | Implicit (relies on embedding model) |
| **Fallback** | None | Dual (AST â†’ LangChain â†’ generic text) |

## AST Parsing Comparison

### rust-code-mcp: Deep Rust Analysis

**Parser:** `RustParser` with tree-sitter-rust

**Symbol Extraction:**
```rust
match node.kind() {
    "function_item" => extract_function(node, source),
    "struct_item" => extract_struct(node, source),
    "trait_item" => extract_trait(node, source),
    "impl_item" => extract_impl(node, source),
    "enum_item" => extract_enum(node, source),
    "mod_item" => extract_module(node, source),
    "const_item" => extract_const(node, source),
    "static_item" => extract_static(node, source),
    "type_item" => extract_type_alias(node, source),
    _ => continue,
}
```

**Extracted Metadata:**
- Symbol name, kind, visibility
- Line range (start_line, end_line, start_byte, end_byte)
- Docstring (/// or //! comments)
- Function modifiers (async, unsafe, const)
- Trait/type names for impl blocks

**Additional Features:**
- **Call Graph:** `CallGraph::build(tree, source)` - directed graph of function calls
- **Imports:** `extract_imports(tree, source)` - use statements
- **Type References:** `TypeReferenceTracker::build()` - type usage tracking

**Language Support:** Rust only (tree-sitter-rust)

### claude-context: Multi-Language Breadth

**Parser:** Generic tree-sitter wrapper with 10 language grammars

**Supported Languages:**
- JavaScript (tree-sitter-javascript)
- TypeScript (tree-sitter-typescript)
- Python (tree-sitter-python)
- Java (tree-sitter-java)
- C++ (tree-sitter-cpp)
- C (tree-sitter-c)
- Go (tree-sitter-go)
- Rust (tree-sitter-rust)
- C# (tree-sitter-csharp)
- Scala (tree-sitter-scala)

**Splittable Node Types:**
- `function_declaration`, `function_definition`
- `class_declaration`, `class_definition`
- `method_declaration`, `method_definition`
- `interface_declaration`
- `module`, `namespace`

**Fallback Chain:**
1. **Primary:** AST splitter (10 languages)
2. **Secondary:** LangChain splitter (20+ languages, character-based)
3. **Tertiary:** Generic text splitter (any content)

**Extracted Metadata:**
- File path
- Language (detected)
- Line ranges (estimated)

**No Additional Features:**
- No call graph
- No import extraction
- No symbol analysis

## Context Enrichment Comparison

### rust-code-mcp: Explicit Context Injection

**Approach:** Anthropic's Contextual Retrieval Pattern

**Implementation:** `format_for_embedding()` in `src/chunker/mod.rs:76-142`

**Components:**
1. **File Context:** Path, line range
2. **Module Context:** Module path (crate::module::submodule)
3. **Symbol Context:** Name, kind, visibility
4. **Documentation:** Docstring extraction
5. **Import Context:** Top 5 import statements
6. **Call Graph Context:** Top 5 outgoing function calls

**Benefit:**
- Provides explicit context for smaller embedding models
- Improves retrieval accuracy with metadata
- Enables relationship-based queries

**Trade-off:**
- +20-30% tokens from metadata overhead
- Rust-specific implementation
- Manual enrichment required per language

### claude-context: Implicit Semantic Understanding

**Approach:** Rely on embedding model's semantic capability

**Implementation:** Direct chunk content embedding (no prefix)

**Components:**
1. **File Metadata:** Path, language
2. **Line Metadata:** Estimated line ranges

**Not Included:**
- No import extraction
- No call graph analysis
- No docstring extraction
- No module path derivation

**Benefit:**
- Multi-language generality (works for any language)
- Simpler implementation
- Lower token overhead

**Trade-off:**
- Requires high-quality embeddings (3072d)
- Less explicit relationship tracking
- Relies on model understanding

---

# MCP Tool Comparison

## Tool Inventory

### rust-code-mcp: 8 Tools

**Search & Discovery (2 tools):**
1. `search` - BM25 keyword search in text files
2. `get_similar_code` - Semantic search via embeddings

**Code Analysis (5 tools):**
3. `find_definition` - Locate symbol definitions
4. `find_references` - Find all symbol usages
5. `get_dependencies` - List file imports
6. `get_call_graph` - Show function call relationships
7. `analyze_complexity` - Calculate code metrics

**File Operations (1 tool):**
8. `read_file_content` - Read any file directly

### claude-context: 4 Tools

**Indexing & Management (3 tools):**
1. `index_codebase` - Start background indexing
2. `get_indexing_status` - Monitor indexing progress
3. `clear_index` - Delete indexed codebase

**Search (1 tool):**
4. `search_code` - Natural language semantic search (hybrid BM25 + vector)

## Detailed Tool Comparison

### Search Functionality

#### rust-code-mcp: `search`

**Signature:**
```rust
{
  directory: String,   // Required: path to search
  keyword: String,     // Required: keyword to search
}
```

**Output:**
```
Search results (3 hits):
Hit: /path/to/file1.rs (Score: 4.28)
Hit: /path/to/file2.rs (Score: 3.91)
Hit: /path/to/file3.rs (Score: 2.15)
```

**Implementation:**
- **Indexing:** On-demand with incremental updates
- **Index:** Persistent Tantivy index in `~/.local/share/rust-code-mcp/`
- **Change Detection:** SHA-256 per-file hashing
- **Cache:** sled KV store for metadata
- **Binary Detection:** Heuristic (null bytes, control chars, UTF-8 validation)

**Performance:**
- First index: ~50-100ms (2 files)
- Subsequent searches: <10ms (unchanged files skipped)
- After file change: ~15-20ms (selective reindexing)

**Limitations:**
- Keyword-based only (not NLP queries)
- Returns file paths, not code snippets
- No result limit parameter

#### claude-context: `search_code`

**Signature:**
```typescript
{
  path: string,              // Required: absolute path
  query: string,             // Required: NLP query
  limit?: number,            // Optional: max results (default 10, max 50)
  extensionFilter?: string[] // Optional: ['.ts', '.py']
}
```

**Output:**
```markdown
Found 3 results for query: "authentication handler"

1. Code snippet (typescript) [my-project]
   Location: src/auth.ts:23-45
   Rank: 1
   Context:
```typescript
export async function authenticate(req: Request) {
  const token = req.headers.get('Authorization');
  // ... implementation
}
```
```

**Implementation:**
- **Indexing:** Pre-indexing required via `index_codebase`
- **Index:** Milvus/Zilliz Cloud (cloud-hosted)
- **Change Detection:** Merkle DAG (milliseconds)
- **Method:** Hybrid (BM25 + dense vector)
- **Embeddings:** OpenAI text-embedding-3-large (3072d)

**Performance:**
- Search latency: 200-1000ms (includes API calls)
- Change detection: <10ms (root hash comparison)

**Advantages:**
- Natural language queries
- Rich markdown output with syntax highlighting
- Code snippets with line ranges
- Extension filtering

### Semantic Search

#### rust-code-mcp: `get_similar_code`

**Signature:**
```rust
{
  query: String,          // Required: code or query
  directory: String,      // Required: codebase path
  limit: Option<usize>,   // Optional: default 5
}
```

**Output:**
```
Found 3 similar code snippet(s) for query 'async function':

1. Score: 0.8532 | File: src/api.rs | Symbol: fetch_data (function)
   Lines: 45-67
   Doc: Fetches data from remote API
   Code preview:
   pub async fn fetch_data() -> Result<Data> {
       let client = Client::new();
       client.get(URL).send().await
```

**Implementation:**
- **Embeddings:** Local (fastembed-rs, all-MiniLM-L6-v2, 384d)
- **Vector DB:** Qdrant (embedded or remote)
- **Similarity:** Cosine similarity
- **Mode:** Vector-only (no BM25 fusion)
- **Cost:** $0 (local inference)

**Advantages:**
- 100% local (no API calls)
- Shows similarity scores
- Includes docstring and code preview
- Zero cost

**Limitations:**
- Lower embedding quality (384d vs 3072d)
- Slower inference (local CPU/GPU)
- No BM25 fusion (pure vector)

#### claude-context: Integrated in `search_code`

**Implementation:**
- **Embeddings:** API-based (text-embedding-3-large, 3072d)
- **Vector DB:** Milvus/Zilliz (cloud)
- **Method:** Hybrid (BM25 + dense vector)
- **Cost:** ~$0.00013 per 1K tokens

**Advantages:**
- Higher embedding quality
- Fast API inference
- Hybrid retrieval (BM25 + vector)

**Limitations:**
- Requires API key
- Code sent to external service
- Recurring costs

### Code Analysis Tools (rust-code-mcp Unique)

#### `find_definition`

**Purpose:** Locate where symbols are defined

**Signature:**
```rust
{
  symbol_name: String,   // Required: symbol to find
  directory: String,     // Required: search directory
}
```

**Output:**
```
Found 2 definition(s) for 'Parser':
- src/parser/mod.rs:45 (struct)
- src/parser/trait.rs:12 (trait)
```

**Use Cases:**
- Navigate to struct definition
- Find function implementation
- Locate trait definition

#### `find_references`

**Purpose:** Find all places where a symbol is used

**Signature:**
```rust
{
  symbol_name: String,   // Required: symbol to find
  directory: String,     // Required: search directory
}
```

**Output:**
```
Found 15 reference(s) to 'Parser' in 5 file(s):

Function Calls (8 references):
- src/main.rs (called by: main, process_file)
- src/indexer.rs (called by: index_code)

Type Usage (7 references):
- src/api.rs (parameter in handle_request)
- src/lib.rs (field 'parser' in struct Context)
- src/types.rs (impl Trait for type)
```

**Use Cases:**
- Find all callers of a function
- Understand where a type is used
- Analyze usage patterns

#### `get_dependencies`

**Purpose:** List all imports for a file

**Signature:**
```rust
{
  file_path: String,   // Required: file to analyze
}
```

**Output:**
```
Dependencies for 'src/parser/mod.rs':

Imports (12):
- std::fs
- std::path::Path
- tree_sitter::Parser
- crate::types::Symbol
```

**Use Cases:**
- Understand file dependencies
- Analyze import structure
- Detect unused imports (potential)

#### `get_call_graph`

**Purpose:** Show function call relationships

**Signature:**
```rust
{
  file_path: String,               // Required: file to analyze
  symbol_name: Option<String>,     // Optional: specific symbol
}
```

**Output (with symbol):**
```
Call graph for 'src/parser/mod.rs':

Symbol: parse_file

Calls (3):
  â†’ fs::read_to_string
  â†’ parse_source
  â†’ extract_symbols

Called by (2):
  â† main
  â† index_code
```

**Output (whole file):**
```
Call graph for 'src/parser/mod.rs':

Functions: 8
Call relationships: 15

Call relationships:
parse_file â†’ [fs::read_to_string, parse_source]
parse_source â†’ [Parser::parse, traverse_node]
traverse_node â†’ [extract_function, extract_struct]
```

**Use Cases:**
- Understand control flow
- Find call chains
- Identify dead code

#### `analyze_complexity`

**Purpose:** Calculate code quality metrics

**Signature:**
```rust
{
  file_path: String,   // Required: file to analyze
}
```

**Output:**
```
Complexity analysis for 'src/parser/mod.rs':

=== Code Metrics ===
Total lines:           808
Non-empty lines:       652
Comment lines:         95
Code lines (approx):   557

=== Symbol Counts ===
Functions:             24
Structs:               5
Traits:                2

=== Complexity ===
Total cyclomatic:      68
Avg per function:      2.83
Function calls:        142
```

**Metrics:**
- Lines of code (total, non-empty, comments, code-only)
- Symbol counts (functions, structs, traits)
- Cyclomatic complexity (if, else if, while, for, match, &&, ||)
- Average complexity per function
- Function call count

**Use Cases:**
- Measure code quality
- Identify refactoring targets
- Track complexity trends

#### `read_file_content`

**Purpose:** Read any file directly

**Signature:**
```rust
{
  file_path: String,   // Required: path to file
}
```

**Output:**
```
{file_content}
```

**Special Cases:**
- "File is empty."
- "The file appears to be a binary file..."

**Binary Detection:**
1. Check for null bytes
2. Count control characters (>10% = binary)
3. Validate UTF-8
4. Check ASCII ratio (>80% = text)

**Use Cases:**
- View source code
- Read configuration files
- Access documentation

### Index Management Tools (claude-context Unique)

#### `index_codebase`

**Purpose:** Start background indexing for a codebase

**Signature:**
```typescript
{
  path: string,                  // Required: absolute path
  force?: boolean,               // Optional: re-index if exists
  splitter?: 'ast' | 'langchain', // Optional: chunking strategy
  customExtensions?: string[],   // Optional: ['.vue', '.svelte']
  ignorePatterns?: string[],     // Optional: exclude patterns
}
```

**Output:**
```
Started background indexing for codebase '/path/to/project' using ast splitter...
```

**Behavior:**
- Returns immediately
- Indexing runs in background
- Monitor with `get_indexing_status`

**Splitter Options:**
- `ast`: Tree-sitter syntax-aware splitting (default)
- `langchain`: Character-based (1000 chars, 200 overlap)

**Use Cases:**
- Index large codebases without blocking
- Configure chunking strategy
- Add custom file extensions

#### `get_indexing_status`

**Purpose:** Check current indexing state

**Signature:**
```typescript
{
  path: string,   // Required: absolute path
}
```

**Output States:**

**Indexed:**
```
âœ… Codebase is fully indexed

Path: /path/to/project
Files indexed: 1,234
Total chunks: 8,567
Last indexed: 2025-10-19 14:23:45
```

**Indexing:**
```
ğŸ”„ Currently being indexed. Progress: 45%

Path: /path/to/project
```

**Failed:**
```
âŒ Indexing failed

Path: /path/to/project
Error: Connection timeout to Milvus

Please try re-indexing with the index_codebase tool.
```

**Not Found:**
```
âŒ Not indexed. Use index_codebase tool to index this codebase first.

Path: /path/to/project
```

**Use Cases:**
- Monitor background indexing
- Verify indexing completion
- Debug indexing failures

#### `clear_index`

**Purpose:** Delete indexed codebase

**Signature:**
```typescript
{
  path: string,   // Required: absolute path
}
```

**Output:**
```
Successfully cleared codebase '/path/to/project'

Remaining indexed codebases: 3
Currently indexing: 0
```

**Use Cases:**
- Remove stale indexes
- Free disk space
- Reset corrupted index

## Tool Capability Matrix

| Capability | rust-code-mcp | claude-context | Winner |
|------------|---------------|----------------|--------|
| **Keyword Search** | âœ… `search` | âœ… `search_code` (hybrid) | Tie |
| **Semantic Search** | âœ… `get_similar_code` | âœ… `search_code` (hybrid) | claude-context (quality) |
| **File Reading** | âœ… `read_file_content` | âŒ | rust-code-mcp |
| **Symbol Definition** | âœ… `find_definition` | âŒ | rust-code-mcp |
| **Reference Finding** | âœ… `find_references` | âŒ | rust-code-mcp |
| **Dependency Analysis** | âœ… `get_dependencies` | âŒ | rust-code-mcp |
| **Call Graph** | âœ… `get_call_graph` | âŒ | rust-code-mcp |
| **Complexity Metrics** | âœ… `analyze_complexity` | âŒ | rust-code-mcp |
| **Index Management** | âŒ | âœ… `clear_index`, `get_indexing_status` | claude-context |
| **Background Indexing** | âŒ | âœ… `index_codebase` | claude-context |
| **Multi-Codebase** | âŒ | âœ… | claude-context |
| **Progress Monitoring** | âŒ | âœ… | claude-context |

**Summary:**
- **rust-code-mcp:** 6 unique code analysis capabilities
- **claude-context:** 3 unique index management capabilities
- **Overlap:** 2 search capabilities (implemented differently)

---

# Performance Characteristics

## Indexing Performance

### First-Time Indexing

**rust-code-mcp:**
- **Trigger:** On-demand during first `search` call
- **Behavior:** Synchronous (blocks until complete)
- **Performance:** ~50-100ms for 2 files
  - Index creation: ~30ms
  - File scanning: ~20ms
  - Tantivy indexing: ~30ms
  - Search query: <10ms
- **Scaling:** O(n) where n = number of files

**claude-context:**
- **Trigger:** Explicit `index_codebase` call
- **Behavior:** Asynchronous (background worker)
- **Performance:** Seconds to minutes (depends on size)
  - File scanning: seconds
  - Merkle tree building: milliseconds
  - Embedding generation: API latency
  - Vector insertion: network latency
- **Scaling:** O(n) for embedding generation, O(log n) for Merkle tree

**Verdict:** rust-code-mcp faster for small codebases (<10 files), claude-context better UX for large codebases (non-blocking)

### Incremental Updates (Change Detection)

**rust-code-mcp:**
- **Method:** SHA-256 per-file hashing
- **Storage:** sled KV store for metadata
- **Process:**
  1. Read file content
  2. Compute SHA-256 hash
  3. Compare with cached hash
  4. Reindex if different
- **Performance:** O(n) - must hash every file
  - Unchanged files: <10ms (skipped)
  - Changed files: ~15-20ms (selective reindexing)
- **Granularity:** File-level only

**claude-context:**
- **Method:** Merkle DAG (tree-based hashing)
- **Storage:** `~/.context/merkle/` snapshots
- **Process:**
  1. **Phase 1:** Compare root hash (milliseconds)
  2. **Phase 2:** Traverse changed subtrees (seconds)
  3. **Phase 3:** Reindex changed files (variable)
- **Performance:** O(log n) for detection, O(m) for reindex (m = changed files)
  - Unchanged project: <10ms (root hash match)
  - Changed files: milliseconds (subtree traversal)
  - Skip rate: 60-80% on typical git workflows
- **Granularity:** Directory-level + file-level

**Verdict:** claude-context 100-1000x faster change detection due to hierarchical Merkle DAG

### Search Latency

**rust-code-mcp:**
- **search tool:** <100ms (BM25 only, local Tantivy)
- **get_similar_code:** 200-1000ms (embedding generation + Qdrant query)
  - Local embedding inference: 100-800ms (depends on CPU/GPU)
  - Qdrant query: <100ms

**claude-context:**
- **search_code:** 200-1000ms (hybrid BM25 + vector)
  - Embedding API call: 100-500ms (network latency)
  - Milvus hybrid query: 100-500ms (network latency)

**Verdict:** rust-code-mcp faster for keyword-only search, similar performance for semantic search

## Embedding Performance

### rust-code-mcp: Local Inference

**Model:** all-MiniLM-L6-v2 (384 dimensions)
**Library:** fastembed-rs
**Cost:** $0 (local CPU/GPU)
**Privacy:** 100% private
**Performance:**
- CPU inference: 100-800ms per batch
- GPU inference: 20-100ms per batch (if available)
- No network latency

**Trade-offs:**
- âœ… Zero cost
- âœ… Complete privacy
- âœ… Offline capability
- âŒ Lower embedding quality
- âŒ Slower inference
- âŒ Requires local compute

### claude-context: API-Based

**Model:** text-embedding-3-large (3072 dimensions)
**Provider:** OpenAI (primary), VoyageAI, Ollama, Gemini
**Cost:** ~$0.00013 per 1K tokens
**Privacy:** Code sent to external API
**Performance:**
- API call: 100-500ms (network latency)
- Batch processing: Efficient
- High-quality embeddings

**Trade-offs:**
- âœ… High-quality embeddings (3072d)
- âœ… Fast API inference
- âœ… Specialized code models (voyage-code-3)
- âŒ Recurring costs
- âŒ Privacy concerns
- âŒ Requires internet

**Verdict:** claude-context has 8x higher dimensional embeddings (better quality), rust-code-mcp has zero cost and full privacy

## Storage Requirements

### rust-code-mcp

**Components:**
- Tantivy index: ~10-50MB per 10k files
- sled metadata cache: ~1-5MB per 10k files
- Qdrant vectors: ~4 bytes Ã— 384 dims Ã— chunk_count
  - Example: 10k chunks = ~15MB
- Total: ~30-70MB per 10k files

**Location:** `~/.local/share/rust-code-mcp/`

### claude-context

**Components:**
- Merkle snapshots: ~1-10MB per codebase
- Milvus vectors: Cloud-hosted (not local)
  - Example: 10k chunks Ã— 3072 dims Ã— 4 bytes = ~120MB (cloud)
- Total local: ~1-10MB per codebase

**Location:** `~/.context/`

**Verdict:** claude-context lower local storage (cloud vectors), rust-code-mcp fully self-contained

## Token Efficiency

### claude-context: Proven Metrics

**Claim:** 40% token reduction vs grep-only approaches

**Source:** [Zilliz Blog - Against Claude Code grep-only](https://zilliz.com/blog/why-im-against-claude-codes-grep-only-retrieval-it-just-burns-too-many-tokens)

**Mechanism:**
- Semantic search retrieves only relevant chunks
- Hybrid BM25+vector reduces false positives
- Merkle DAG prevents redundant reindexing

### rust-code-mcp: Not Benchmarked

**Theoretical Benefits:**
- Symbol-based chunking reduces irrelevant code
- Rich context improves retrieval precision
- Hybrid search (BM25 + vector) reduces noise

**Theoretical Overhead:**
- +20-30% tokens from metadata prefix in embeddings
- Variable chunk sizes may include more context than needed

**Verdict:** claude-context has proven token reduction, rust-code-mcp needs benchmarking

---

# Production Readiness

## rust-code-mcp Maturity

**Status:** Phase 7 Complete - Testing Phase

**Strengths:**
- âœ… 8 specialized tools implemented
- âœ… Comprehensive testing (45 passing tests)
- âœ… Integration verified with Claude Code
- âœ… Robust error handling (McpError)
- âœ… Binary file detection
- âœ… Persistent index (Tantivy, Qdrant, sled)

**Limitations:**
- âŒ Rust-only language support
- âŒ SHA-256 change detection (slow for large projects)
- âŒ Synchronous indexing (blocks on first search)
- âŒ No index management tools (clear, status)
- âŒ No multi-codebase tracking
- âŒ No progress monitoring
- âŒ Relative path acceptance (should require absolute)
- âŒ Plain text output (not markdown)

**Roadmap:**
- **Phase 8:** Optimization & release
  - Merkle tree change detection (critical)
  - Async indexing workflow
  - Index management tools
  - Multi-language support
  - Markdown output formatting

**Deployment:**
- Install: `cargo build --release`
- Binary: `./target/release/file-search-mcp`
- Dependencies: Rust toolchain only
- Config: Environment variables (RUST_LOG, QDRANT_MODE)

## claude-context Maturity

**Status:** Production - Deployed across organizations

**Strengths:**
- âœ… Proven token reduction (40% vs grep)
- âœ… Multi-language support (20+ languages)
- âœ… Millisecond change detection (Merkle DAG)
- âœ… Async background indexing
- âœ… Progress monitoring (get_indexing_status)
- âœ… Index management (clear_index)
- âœ… Professional documentation
- âœ… Markdown output with syntax highlighting
- âœ… Absolute path requirement
- âœ… Graceful error handling (dual fallback)
- âœ… Multi-codebase management

**Limitations:**
- âŒ Requires external services (OpenAI, Milvus/Zilliz)
- âŒ Recurring API costs ($$$)
- âŒ Code sent to external APIs (privacy concern)
- âŒ No deep code analysis tools (call graphs, complexity, references)

**Deployment:**
- Install: `npm install -g @zilliz/claude-context-mcp`
- Run: `npx @zilliz/claude-context-mcp`
- Dependencies: Node.js runtime
- Config: `~/.context/.env` (API keys, Milvus connection)

**Verdict:** claude-context is production-ready with proven metrics, rust-code-mcp needs Phase 8 improvements

---

# Recommendations

## For rust-code-mcp Development

### Priority 1: Critical (Phase 8 Blockers)

#### 1. Implement Merkle DAG Change Detection

**Rationale:** claude-context proves this is 100-1000x faster than SHA-256

**Implementation:**
```rust
// Add dependency
rs_merkle = "1.4"

// Build Merkle tree on index
pub struct MerkleSnapshot {
    root_hash: [u8; 32],
    tree: MerkleTree,
    timestamp: SystemTime,
}

// Cache snapshot
impl MerkleSnapshot {
    fn save(&self, path: &Path) -> Result<()>;
    fn load(path: &Path) -> Result<Self>;
    fn compare(&self, other: &Self) -> Vec<PathBuf>; // Changed files
}

// Use in incremental indexing
fn detect_changes(dir: &Path) -> Result<Vec<PathBuf>> {
    let current = build_merkle_tree(dir)?;
    let cached = MerkleSnapshot::load(snapshot_path)?;

    if current.root_hash == cached.root_hash {
        return Ok(vec![]); // No changes (milliseconds)
    }

    Ok(current.compare(&cached)) // Find changed files
}
```

**Impact:**
- 100-1000x faster change detection on large codebases
- Directory-level skipping (60-80% skip rate)
- Millisecond root hash comparison vs seconds for SHA-256

---

#### 2. Decouple Indexing from Search (Async Workflow)

**Rationale:** Blocking on first search is poor UX, doesn't scale to large codebases

**Implementation:**

**Add new tool: `index_codebase`**
```rust
#[derive(Debug, Deserialize)]
struct IndexCodebaseArgs {
    directory: String,
    force: Option<bool>,
}

async fn handle_index_codebase(args: IndexCodebaseArgs) -> Result<CallToolResult> {
    let path = PathBuf::from(&args.directory);

    // Spawn background indexing task
    tokio::spawn(async move {
        index_directory(&path).await
    });

    Ok(CallToolResult {
        content: vec![Content::text(
            format!("Started background indexing for '{}'...", args.directory)
        )],
        isError: None,
    })
}
```

**Add new tool: `get_indexing_status`**
```rust
#[derive(Debug, Deserialize)]
struct GetStatusArgs {
    directory: String,
}

async fn handle_get_indexing_status(args: GetStatusArgs) -> Result<CallToolResult> {
    let status = IndexingStatus::get(&args.directory)?;

    let text = match status {
        IndexingStatus::NotStarted => "âŒ Not indexed. Use index_codebase tool first.",
        IndexingStatus::Indexing { progress } => {
            format!("ğŸ”„ Currently being indexed. Progress: {}%", progress)
        }
        IndexingStatus::Completed { files, chunks, timestamp } => {
            format!(
                "âœ… Codebase is fully indexed\n\n\
                 Files indexed: {}\n\
                 Total chunks: {}\n\
                 Last indexed: {}",
                files, chunks, timestamp
            )
        }
        IndexingStatus::Failed { error } => {
            format!("âŒ Indexing failed\n\nError: {}", error)
        }
    };

    Ok(CallToolResult {
        content: vec![Content::text(text)],
        isError: status.is_error(),
    })
}
```

**Impact:**
- Better user experience (non-blocking)
- Matches claude-context workflow
- Enables progress monitoring

---

### Priority 2: High (Production Hardening)

#### 3. Add `clear_index` Tool

**Rationale:** Users need index lifecycle management

**Implementation:**
```rust
#[derive(Debug, Deserialize)]
struct ClearIndexArgs {
    directory: String,
}

async fn handle_clear_index(args: ClearIndexArgs) -> Result<CallToolResult> {
    let path = PathBuf::from(&args.directory);

    // Clear Tantivy index
    let index_dir = get_index_path(&path);
    if index_dir.exists() {
        fs::remove_dir_all(&index_dir)?;
    }

    // Clear metadata cache
    let cache_dir = get_cache_path(&path);
    if cache_dir.exists() {
        fs::remove_dir_all(&cache_dir)?;
    }

    // Clear Qdrant collection
    let collection_name = get_collection_name(&path);
    qdrant_client.delete_collection(&collection_name).await?;

    // Clear Merkle snapshot
    let merkle_path = get_merkle_snapshot_path(&path);
    if merkle_path.exists() {
        fs::remove_file(&merkle_path)?;
    }

    Ok(CallToolResult {
        content: vec![Content::text(
            format!("Successfully cleared codebase '{}'", args.directory)
        )],
        isError: None,
    })
}
```

**Impact:**
- Complete index lifecycle management
- Enables cache invalidation
- Frees disk space

---

#### 4. Require Absolute Paths in All Tools

**Rationale:** Prevents ambiguity, matches claude-context best practice

**Implementation:**
```rust
fn validate_absolute_path(path: &str) -> Result<PathBuf> {
    let p = PathBuf::from(path);

    if !p.is_absolute() {
        return Err(McpError::invalid_params(
            format!("Path must be absolute, got: {}", path)
        ));
    }

    if !p.exists() {
        return Err(McpError::invalid_params(
            format!("Path does not exist: {}", path)
        ));
    }

    Ok(p)
}

// Use in all tools
async fn handle_search(args: SearchArgs) -> Result<CallToolResult> {
    let directory = validate_absolute_path(&args.directory)?;
    // ... rest of implementation
}
```

**Impact:**
- More reliable behavior
- Consistent with other MCP servers
- Prevents working directory confusion

---

#### 5. Adopt Markdown Output Formatting

**Rationale:** Better readability for LLMs and users, consistent with MCP ecosystem

**Implementation:**
```rust
// search tool
fn format_search_results(hits: Vec<Hit>) -> String {
    let mut output = format!("# Search Results ({} hits)\n\n", hits.len());

    for (i, hit) in hits.iter().enumerate() {
        output.push_str(&format!(
            "## {}. {}\n**Score:** {:.2}\n\n",
            i + 1,
            hit.path.display(),
            hit.score
        ));
    }

    output
}

// get_similar_code tool
fn format_similar_code(results: Vec<CodeMatch>) -> String {
    let mut output = format!("# Similar Code ({} results)\n\n", results.len());

    for (i, result) in results.iter().enumerate() {
        output.push_str(&format!(
            "## {}. {} ({})\n\n\
             **Score:** {:.4}\n\
             **Location:** {}:{}-{}\n\
             **Symbol:** {} ({})\n\n\
             ### Documentation\n\
             {}\n\n\
             ### Code\n\
             ```rust\n{}\n```\n\n",
            i + 1,
            result.file_path.display(),
            result.language,
            result.score,
            result.file_path.display(),
            result.start_line,
            result.end_line,
            result.symbol_name,
            result.symbol_kind,
            result.docstring.as_deref().unwrap_or("_No documentation_"),
            result.code_preview
        ));
    }

    output
}

// analyze_complexity tool
fn format_complexity_analysis(analysis: ComplexityAnalysis) -> String {
    format!(
        "# Complexity Analysis\n\n\
         **File:** `{}`\n\n\
         ## Code Metrics\n\n\
         | Metric | Value |\n\
         |--------|-------|\n\
         | Total lines | {} |\n\
         | Non-empty lines | {} |\n\
         | Comment lines | {} |\n\
         | Code lines (approx) | {} |\n\n\
         ## Symbol Counts\n\n\
         | Symbol | Count |\n\
         |--------|-------|\n\
         | Functions | {} |\n\
         | Structs | {} |\n\
         | Traits | {} |\n\n\
         ## Complexity\n\n\
         | Metric | Value |\n\
         |--------|-------|\n\
         | Total cyclomatic | {} |\n\
         | Avg per function | {:.2} |\n\
         | Function calls | {} |\n",
        analysis.file_path.display(),
        analysis.total_lines,
        analysis.non_empty_lines,
        analysis.comment_lines,
        analysis.code_lines,
        analysis.function_count,
        analysis.struct_count,
        analysis.trait_count,
        analysis.total_complexity,
        analysis.avg_complexity,
        analysis.call_count
    )
}
```

**Impact:**
- Improved presentation
- Better LLM parsing
- Consistency with other MCP servers

---

### Priority 3: Medium (API Improvements)

#### 6. Add Configurable Result Limits with Maximums

**Rationale:** Prevent excessive results, match claude-context API

**Implementation:**
```rust
#[derive(Debug, Deserialize)]
struct SearchArgs {
    directory: String,
    keyword: String,
    #[serde(default = "default_limit")]
    limit: usize,
}

fn default_limit() -> usize { 10 }

async fn handle_search(args: SearchArgs) -> Result<CallToolResult> {
    let limit = args.limit.min(50); // Cap at 50
    let searcher = index.reader()?.searcher();
    let top_docs = searcher.search(&query, &TopDocs::with_limit(limit))?;
    // ... rest
}

#[derive(Debug, Deserialize)]
struct GetSimilarCodeArgs {
    query: String,
    directory: String,
    #[serde(default = "default_similar_limit")]
    limit: usize,
}

fn default_similar_limit() -> usize { 5 }

async fn handle_get_similar_code(args: GetSimilarCodeArgs) -> Result<CallToolResult> {
    let limit = args.limit.min(20); // Cap at 20
    let results = qdrant_search(&args.query, limit).await?;
    // ... rest
}
```

**Impact:**
- Better performance (bounded results)
- Consistent API with other MCP servers
- Prevents overwhelming output

---

#### 7. Implement Relative Path Display

**Rationale:** Shorter, more readable than absolute paths

**Implementation:**
```rust
struct SearchContext {
    base_dir: PathBuf,
}

impl SearchContext {
    fn relative_path(&self, absolute: &Path) -> PathBuf {
        absolute.strip_prefix(&self.base_dir)
            .unwrap_or(absolute)
            .to_path_buf()
    }
}

// Use in output formatting
fn format_search_results(hits: Vec<Hit>, context: &SearchContext) -> String {
    let mut output = String::new();

    for hit in hits {
        let rel_path = context.relative_path(&hit.path);
        output.push_str(&format!(
            "## {}\n**Score:** {:.2}\n\n",
            rel_path.display(),
            hit.score
        ));
    }

    output
}
```

**Impact:**
- Cleaner output
- Better readability
- Consistent with claude-context

---

#### 8. Add Line Range Support (start-end)

**Rationale:** More context than single line number

**Implementation:**
```rust
pub struct SymbolRange {
    pub start_line: usize,
    pub end_line: usize,   // Add this
    pub start_byte: usize,
    pub end_byte: usize,
}

// Update output formatting
fn format_definition_location(symbol: &Symbol) -> String {
    format!(
        "{}:{}-{} ({})",
        symbol.file_path.display(),
        symbol.range.start_line,
        symbol.range.end_line,
        symbol.kind
    )
}
```

**Impact:**
- Better location information
- Shows symbol size at a glance
- Matches claude-context format

---

### Priority 4: Future Enhancements

#### 9. Multi-Language Support

**Rationale:** Expand beyond Rust-only

**Strategy:**
- Add tree-sitter grammars for TypeScript, Python, Go (priority languages)
- Implement generic symbol extractors (function, class, method)
- Keep deep enrichment (imports, calls) for supported languages
- Use rust-code-mcp's chunking strategy for all

**Implementation:**
```rust
pub enum Language {
    Rust,
    TypeScript,
    Python,
    Go,
}

pub trait Parser {
    fn parse(&self, source: &str) -> Result<Vec<Symbol>>;
    fn extract_imports(&self, tree: &Tree, source: &str) -> Vec<Import>;
    fn build_call_graph(&self, tree: &Tree, source: &str) -> CallGraph;
}

pub struct RustParser { /* existing */ }
pub struct TypeScriptParser { /* new */ }
pub struct PythonParser { /* new */ }
pub struct GoParser { /* new */ }

impl Parser for RustParser { /* existing */ }
impl Parser for TypeScriptParser { /* implement */ }
impl Parser for PythonParser { /* implement */ }
impl Parser for GoParser { /* implement */ }
```

**Impact:**
- Broader applicability
- Maintains deep analysis advantage
- Competitive with claude-context

---

#### 10. Configurable Chunking Strategies

**Rationale:** Match claude-context flexibility

**Implementation:**
```rust
#[derive(Debug, Deserialize)]
struct IndexCodebaseArgs {
    directory: String,
    force: Option<bool>,
    #[serde(default)]
    splitter: SplitterType,
}

#[derive(Debug, Deserialize)]
enum SplitterType {
    #[serde(rename = "ast")]
    Ast,
    #[serde(rename = "text")]
    Text,
}

impl Default for SplitterType {
    fn default() -> Self { Self::Ast }
}

// Implement text-based splitter
pub struct TextSplitter {
    chunk_size: usize,
    overlap: usize,
}

impl TextSplitter {
    fn split(&self, content: &str) -> Vec<String> {
        // Character-based splitting with overlap
    }
}
```

**Impact:**
- Better handling of non-code content
- Flexibility for different use cases

---

## Strategic Positioning

### rust-code-mcp Unique Value Proposition

**Tagline:** "Privacy-First Code Intelligence for Rust"

**Differentiators:**
1. **100% Local Operation**
   - No API calls
   - No external dependencies
   - Complete privacy guarantee
   - Offline capability

2. **Deep Code Analysis**
   - Call graphs
   - Complexity metrics
   - Reference finding
   - Dependency tracking
   - Symbol definitions

3. **Zero Cost**
   - No subscriptions
   - No API fees
   - No recurring charges
   - Self-hosted infrastructure

4. **Rust-Specific Optimization**
   - Deep AST parsing
   - Rust symbol extraction
   - Cargo integration (future)

**Target Users:**
- Privacy-conscious developers
- Open-source projects
- Air-gapped/offline environments
- Cost-sensitive individuals/teams
- Rust developers needing deep analysis

**Marketing Messages:**
- "All the power of claude-context, 100% local, $0 cost"
- "Code intelligence without compromising privacy"
- "Deep Rust analysis that stays on your machine"

---

### When to Use Each System

#### Choose rust-code-mcp When:
- âœ… Privacy is critical (no code leaving machine)
- âœ… Working offline/air-gapped
- âœ… Zero budget for tools
- âœ… Deep Rust code analysis needed
- âœ… Small to medium codebase (<100k LOC)
- âœ… Need call graphs, complexity, references
- âœ… Prototyping/development phase

#### Choose claude-context When:
- âœ… Large-scale production codebase (>100k LOC)
- âœ… Multi-language project (10+ languages)
- âœ… Natural language queries important
- âœ… Team environment (shared cloud storage)
- âœ… API costs acceptable (~$10-50/month)
- âœ… Need proven 40% token reduction
- âœ… Fast change detection critical (Merkle DAG)

#### Hybrid Approach (Future):
Combine best of both:
1. Use **claude-context** for multi-language semantic search
2. Use **rust-code-mcp** for deep Rust analysis (call graphs, complexity)
3. Keep sensitive code analysis local (rust-code-mcp)
4. Use cloud for public/open-source code (claude-context)

---

## Conclusion

### Summary of Findings

**rust-code-mcp** and **claude-context** represent two complementary approaches to code intelligence:

**rust-code-mcp strengths:**
- Privacy-first local architecture
- Deep code analysis capabilities (6 unique tools)
- Rich context enrichment (Anthropic pattern)
- Zero cost, zero external dependencies
- Symbol-based semantic chunking

**rust-code-mcp weaknesses:**
- Single language (Rust only)
- Slow change detection (SHA-256)
- Synchronous indexing workflow
- No index management tools
- Testing phase maturity

**claude-context strengths:**
- Production-proven (40% token reduction)
- Multi-language (20+ languages)
- Millisecond change detection (Merkle DAG)
- Async background indexing
- Professional documentation

**claude-context weaknesses:**
- Privacy concerns (API-based)
- Recurring costs ($$$)
- No deep code analysis tools
- Limited context enrichment

### Final Recommendation

**For rust-code-mcp to reach production parity:**

**Critical (Phase 8):**
1. âœ… Implement Merkle DAG change detection
2. âœ… Decouple indexing from search (async workflow)
3. âœ… Add index management tools (clear, status)
4. âœ… Require absolute paths
5. âœ… Adopt markdown output

**High Priority:**
6. âœ… Configurable result limits
7. âœ… Relative path display
8. âœ… Line range support

**Future:**
9. â³ Multi-language support (TypeScript, Python, Go)
10. â³ Configurable chunking strategies

**With these improvements, rust-code-mcp will offer:**
- Best-in-class privacy and cost (local, free)
- Production-ready performance (Merkle DAG)
- Unique code analysis capabilities (call graphs, complexity, references)
- Competitive search quality (hybrid BM25 + vector)
- Professional UX (async indexing, markdown output)

**Positioning:** "The privacy-first alternative to claude-context with deep code intelligence"

---

## Metadata

**Analysis Date:** 2025-10-19
**rust-code-mcp Version:** Phase 7 Complete (Commit d567edd)
**claude-context Version:** @zilliz/claude-context-mcp@latest
**Analysis Method:** Direct source code examination + official documentation
**Confidence Level:** High (based on actual implementation review)

**Sources:**
- rust-code-mcp repository: `/home/molaco/Documents/rust-code-mcp/`
- claude-context repository: `https://github.com/zilliztech/claude-context`
- npm package: `https://www.npmjs.com/package/@zilliz/claude-context-mcp`
- Zilliz blog: Token reduction analysis
- Technical documentation: Build Code Retrieval guides

**Document Version:** 2.0 (Combined Chunking + Tools Analysis)
